{
  "project_name": "DGSP",
  "config_name": "config_nli_adpxt.json",
  "job_name": {
    "name": [
      "tra-adpxt-s1",
      "tra-adpxt-s2",
      "tra-adpxt-s3",
      "tra-adpxt-s4",
      "tra-adpxt-s5"
    ]
  },
  "arch": {
    "plm": "roberta-base",
    "tokenizer": "roberta-base"
  },
  "train_type": "adpxt",
  "template": "type0",
  "hyperparam": {
    "global_length": [
      32,
      32,
      32,
      32,
      32
    ],
    "context_length": [
      4,
      4,
      4,
      4,
      4
    ],
    "alpha": 0.1,
    "drop_out": 0.1
  },
  "seed": [
    10,
    20,
    30,
    40,
    50
  ],
  "shots": 0,
  "task": "nli",
  "freeze_plm": true,
  "adversarial": true,
  "data_loader": {
    "dataset": "mnli",
    "args": {
      "training_setting": "leave-one-domain-out",
      "source_domains": [
        "fiction",
        "government",
        "slate",
        "telephone"
      ],
      "target_domain": "travel",
      "data_dir": "data/NLI/MNLI_sub",
      "batch_size": [
        16,
        16,
        16,
        16,
        16
      ],
      "dev_batch_size": 16,
      "shuffle": true
    }
  },
  "optimizer": {
    "type": "adamw",
    "args": {
      "model_lr": [
        1e-2,
        1e-2,
        1e-2,
        1e-2,
        1e-2
      ],
      "disc_lr": [
        1e-2,
        1e-2,
        1e-2,
        1e-2,
        1e-2
      ],
      "weight_decay": 1e-2
    }
  },
  "lr_scheduler": {
    "type": "linear",
    "args": {
      "warm_up": 0.06
    }
  },
  "trainer": {
    "epochs": 20,
    "early_stop": false
  }
}



